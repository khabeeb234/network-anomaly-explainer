"""
utils.py ‚Äî Network Anomaly Explainer (Final, Rate-Limit-Safe)
-------------------------------------------------------------
Features:
 - IsolationForest anomaly detection
 - Gemini 2.5 Flash ‚Üí auto fallback to Pro model
 - Handles finish_reason = 2 safely
 - Rule-based fallback when AI unavailable
 - Built-in delay to avoid Gemini free-tier 429s
 - Streamlit connection checker
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from dateutil import parser
import os
import datetime
import logging
import time   # üëà for API delay handling

# ===============================================================
# Logging
# ===============================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)

# ===============================================================
# 1Ô∏è‚É£ LOADERS
# ===============================================================
def load_metrics(path):
    df = pd.read_csv(path, parse_dates=["timestamp"])
    return df.sort_values("timestamp").reset_index(drop=True)

def load_changes(path):
    df = pd.read_csv(path, parse_dates=["timestamp"])
    return df.sort_values("timestamp").reset_index(drop=True)

# ===============================================================
# 2Ô∏è‚É£ ANOMALY DETECTION
# ===============================================================
def detect_anomalies_isolationforest(
    df,
    features=["latency_ms","packet_loss","throughput_mbps"],
    contamination=0.1,
    random_state=42
):
    X = df[features].fillna(0).values
    model = IsolationForest(contamination=contamination, random_state=random_state)
    model.fit(X)
    df["anomaly_isof"] = model.predict(X) == -1
    df["iso_score"] = model.decision_function(X)
    return df, model

# ===============================================================
# 3Ô∏è‚É£ CHANGE CORRELATION
# ===============================================================
def simple_time_correlation(row_ts, changes_df, window_seconds=300):
    if changes_df is None or changes_df.empty:
        return []
    diffs = (changes_df["timestamp"] - row_ts).dt.total_seconds().abs()
    return changes_df[diffs <= window_seconds].to_dict("records")

def format_changes_summary(change_records):
    if not change_records:
        return None
    return "; ".join([
        f"{r['timestamp'].strftime('%Y-%m-%d %H:%M:%S')} - {r['event']}"
        + (f" ({r.get('details')})" if r.get('details') else "")
        for r in change_records
    ])

# ===============================================================
# 4Ô∏è‚É£ GEMINI AI EXPLANATION (Flash ‚Üí Pro Fallback)
# ===============================================================
def generate_explanation(row, change_records=None, use_llm=True, max_tokens=256):
    change_summary = format_changes_summary(change_records) if change_records else None

    prompt = f"""
You are a senior network reliability engineer diagnosing performance anomalies.

Metrics:
- Timestamp: {row['timestamp']}
- Latency: {row['latency_ms']} ms
- Packet loss: {row['packet_loss']} %
- Throughput: {row['throughput_mbps']} Mbps
- ML flag: {bool(row.get('anomaly_isof', False))}

Changes:
{change_summary or 'No related configuration or routing updates.'}

Give a concise, 3‚Äì4 sentence summary:
1Ô∏è‚É£ Likely cause (general)
2Ô∏è‚É£ User impact
3Ô∏è‚É£ Verification steps
Keep tone professional and safe.
"""

    gemini_key = os.environ.get("GEMINI_API_KEY")
    model_used = "Rule-based"
    if use_llm and gemini_key:
        try:
            import google.generativeai as genai
            genai.configure(api_key=gemini_key)

            def try_model(model_name):
                model = genai.GenerativeModel(model_name)
                resp = model.generate_content(
                    prompt,
                    generation_config={"temperature":0.7,"max_output_tokens":max_tokens}
                )
                if hasattr(resp, "candidates") and resp.candidates:
                    for cand in resp.candidates:
                        if hasattr(cand, "content") and cand.content:
                            for p in cand.content.parts:
                                if hasattr(p, "text") and p.text:
                                    return p.text.strip()
                return None

            output = try_model("gemini-2.5-flash")
            model_used = "Gemini 2.5 Flash"

            if not output:
                print("‚ö†Ô∏è Retrying with Gemini 2.5 Pro due to filtered/empty output‚Ä¶")
                output = try_model("gemini-2.5-pro")
                model_used = "Gemini 2.5 Pro"

            if output:
                return f"{output}\n\n*Generated by {model_used}*"
            else:
                return f"AI model returned no content (possibly filtered).\n\n*Generated by {model_used}*"

        except Exception as e:
            print(f"‚ö†Ô∏è Gemini AI generation failed: {e}")

    # ---------------- RULE-BASED FALLBACK ----------------
    reasons, checks = [], []
    if row.get("latency_ms",0)>150: 
        reasons.append("high latency"); checks.append("check routing or uplink congestion")
    if row.get("packet_loss",0)>1.0: 
        reasons.append("packet loss"); checks.append("inspect QoS drops or interface errors")
    if row.get("throughput_mbps",0)<50: 
        reasons.append("low throughput"); checks.append("verify bandwidth limits or shaping")

    change_text = f"Correlated changes: {change_summary}" if change_summary else "No config changes found."
    if reasons:
        return f"Detected {', and '.join(reasons)}. {change_text}. Likely cause: transient congestion or route update. Recommended: {', then '.join(checks[:2])}.\n\n*Generated by Rule-based fallback*"
    return f"Anomaly flagged by ML model. {change_text}. Check CPU/memory and interface health.\n\n*Generated by Rule-based fallback*"

# ===============================================================
# 5Ô∏è‚É£ BUILD REPORT (WITH RATE-LIMIT DELAY)
# ===============================================================
import time

def build_report(metrics_df, changes_df, window_seconds=300, use_llm=True):
    """Generate AI explanations with delay to respect free-tier rate limits."""
    anomalies = []

    for _, row in metrics_df.iterrows():
        if row.get("anomaly_isof", False):
            change_records = simple_time_correlation(row["timestamp"], changes_df, window_seconds)
            explanation = generate_explanation(row, change_records, use_llm=use_llm)
            anomalies.append({
                "timestamp": row["timestamp"],
                "latency_ms": row["latency_ms"],
                "packet_loss": row["packet_loss"],
                "throughput_mbps": row["throughput_mbps"],
                "changes": change_records,
                "explanation": explanation
            })

            # üïí Respect Gemini free-tier limit (‚âà 2 req/min)
            if use_llm:
                print("‚è≥ Waiting 20 s to respect Gemini API quota‚Ä¶")
                time.sleep(20)

    if not anomalies:
        print("‚úÖ No anomalies detected.")
    else:
        print(f"‚úÖ Generated explanations for {len(anomalies)} anomalies.")

    return anomalies

# ===============================================================
# 6Ô∏è‚É£ GEMINI CONNECTION CHECK
# ===============================================================
def check_gemini_connection():
    try:
        import google.generativeai as genai
        gemini_key = os.environ.get("GEMINI_API_KEY")
        if not gemini_key:
            return False, "‚ö†Ô∏è GEMINI_API_KEY not set ‚Äî using rule-based fallback."
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel("gemini-2.5-flash")
        _ = model.generate_content("Hello from Gemini AI!")
        return True, "‚úÖ Connected to Gemini 2.5 Flash"
    except Exception as e:
        return False, f"‚ö†Ô∏è Gemini connection failed: {e}"
